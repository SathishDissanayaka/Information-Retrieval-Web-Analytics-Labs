{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": { 
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQm3L5ff/+Xu+Vb2ReeU60",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SathishDissanayaka/Information-Retrieval-Web-Analytics-Labs/blob/main/IRWA_Lab04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SyzdxA1hwG9",
        "outputId": "5a2833d0-6746-41d5-85dd-b9a8ebe47e1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$this$is$the$best$month$\n",
            "['$t', 'th', 'hi', 'is', 's$', '$i', 'is', 's$', '$t', 'th', 'he', 'e$', '$b', 'be', 'es', 'st', 't$', '$m', 'mo', 'on', 'nt', 'th', 'h$']\n"
          ]
        }
      ],
      "source": [
        "#Q1 Part A(k-grams)\n",
        "from nltk.util import ngrams\n",
        "\n",
        "text=\"this is the best month\"\n",
        "# text_new=\"this is the best month\".replace(\" \",\"$\")+\"$\" ,output->\"this$is$the$best$month$\"\n",
        "\n",
        "text_new=\"$\"+text.replace(\" \",\"$\")+\"$\"\n",
        "print(text_new)\n",
        "\n",
        "kGram1 = ngrams(text_new, 2) #Creates bigrams (k=2) from the string text_new\n",
        "\n",
        "kGramArray = [\"\".join(kGramTuple) for kGramTuple in kGram1]\n",
        "#For each tuple (like ('t','h')) generated by ngrams, it joins the characters into a string. Example: ('t','h') → \"th\"\n",
        "print(kGramArray)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def grams(doc, y): #Uses to generate all substrings of length y (character-based n-grams).\n",
        "  doc = \"$\" + doc.replace(\" \", \"$\") + \"$\"\n",
        "  grammed_str = ngrams(doc, y)\n",
        "  grammed_list = [\"\".join(i) for i in grammed_str]\n",
        "\n",
        "  return grammed_list\n",
        "\n",
        "doc1 = \"I am sam\"\n",
        "print(grams(doc1, 1))\n",
        "print(grams(doc1, 2))\n",
        "print(grams(doc1, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KcqQfB4DhS2",
        "outputId": "6d48d790-bde7-41a0-dcf7-d88e2ee24519"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['$', 'I', '$', 'a', 'm', '$', 's', 'a', 'm', '$']\n",
            "['$I', 'I$', '$a', 'am', 'm$', '$s', 'sa', 'am', 'm$']\n",
            "['$I$', 'I$a', '$am', 'am$', 'm$s', '$sa', 'sam', 'am$']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g1 = ngrams(text_new, 1)\n",
        "g1_list = [\"\".join(i) for i in g1]\n",
        "print(g1_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dlMe7CPDmVr",
        "outputId": "99f506d3-0b5b-44a3-c3e2-33e8f3eb717a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['$', 't', 'h', 'i', 's', '$', 'i', 's', '$', 't', 'h', 'e', '$', 'b', 'e', 's', 't', '$', 'm', 'o', 'n', 't', 'h', '$']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g2=ngrams(text_new,2)\n",
        "g2_list=[\"\".join(i) for i in g2]\n",
        "print(g2_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcSaY3mADpAW",
        "outputId": "3478b546-8ef9-4d38-fa51-c44ca25a43fe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['$t', 'th', 'hi', 'is', 's$', '$i', 'is', 's$', '$t', 'th', 'he', 'e$', '$b', 'be', 'es', 'st', 't$', '$m', 'mo', 'on', 'nt', 'th', 'h$']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g3 = ngrams(text_new, 3)\n",
        "g3_list = [\"\".join(i) for i in g3]\n",
        "print(g3_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xFm2UEiDrTq",
        "outputId": "d6d1e398-10e7-4b77-c909-4415099cf765"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['$th', 'thi', 'his', 'is$', 's$i', '$is', 'is$', 's$t', '$th', 'the', 'he$', 'e$b', '$be', 'bes', 'est', 'st$', 't$m', '$mo', 'mon', 'ont', 'nth', 'th$']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exact Answer for the question\n",
        "from nltk.util import ngrams\n",
        "\n",
        "# Function to generate k-grams\n",
        "def grams(doc, k):\n",
        "    # Add boundary markers and replace spaces\n",
        "    doc = \"$\" + doc.replace(\" \", \"$\") + \"$\"\n",
        "    grammed_str = ngrams(doc, k)\n",
        "    grammed_list = [\"\".join(i) for i in grammed_str]\n",
        "    return grammed_list\n",
        "\n",
        "# Corpus\n",
        "corpus = {\n",
        "    \"D1\": \"I am Sam.\",\n",
        "    \"D2\": \"Sam I am.\",\n",
        "    \"D3\": \"I do not like green eggs and ham.\",\n",
        "    \"D4\": \"I do not like them, Sam I am.\"\n",
        "}\n",
        "\n",
        "# Generate k-grams for each document\n",
        "for doc_id, text in corpus.items():\n",
        "    print(f\"\\n{doc_id}: {text}\")\n",
        "    for k in [1, 2, 3]:\n",
        "        print(f\" {k}-grams: {grams(text, k)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQMj6hUlIxkv",
        "outputId": "a535e11f-d191-4b69-e0ae-a9693566d5fb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "D1: I am Sam.\n",
            " 1-grams: ['$', 'I', '$', 'a', 'm', '$', 'S', 'a', 'm', '.', '$']\n",
            " 2-grams: ['$I', 'I$', '$a', 'am', 'm$', '$S', 'Sa', 'am', 'm.', '.$']\n",
            " 3-grams: ['$I$', 'I$a', '$am', 'am$', 'm$S', '$Sa', 'Sam', 'am.', 'm.$']\n",
            "\n",
            "D2: Sam I am.\n",
            " 1-grams: ['$', 'S', 'a', 'm', '$', 'I', '$', 'a', 'm', '.', '$']\n",
            " 2-grams: ['$S', 'Sa', 'am', 'm$', '$I', 'I$', '$a', 'am', 'm.', '.$']\n",
            " 3-grams: ['$Sa', 'Sam', 'am$', 'm$I', '$I$', 'I$a', '$am', 'am.', 'm.$']\n",
            "\n",
            "D3: I do not like green eggs and ham.\n",
            " 1-grams: ['$', 'I', '$', 'd', 'o', '$', 'n', 'o', 't', '$', 'l', 'i', 'k', 'e', '$', 'g', 'r', 'e', 'e', 'n', '$', 'e', 'g', 'g', 's', '$', 'a', 'n', 'd', '$', 'h', 'a', 'm', '.', '$']\n",
            " 2-grams: ['$I', 'I$', '$d', 'do', 'o$', '$n', 'no', 'ot', 't$', '$l', 'li', 'ik', 'ke', 'e$', '$g', 'gr', 're', 'ee', 'en', 'n$', '$e', 'eg', 'gg', 'gs', 's$', '$a', 'an', 'nd', 'd$', '$h', 'ha', 'am', 'm.', '.$']\n",
            " 3-grams: ['$I$', 'I$d', '$do', 'do$', 'o$n', '$no', 'not', 'ot$', 't$l', '$li', 'lik', 'ike', 'ke$', 'e$g', '$gr', 'gre', 'ree', 'een', 'en$', 'n$e', '$eg', 'egg', 'ggs', 'gs$', 's$a', '$an', 'and', 'nd$', 'd$h', '$ha', 'ham', 'am.', 'm.$']\n",
            "\n",
            "D4: I do not like them, Sam I am.\n",
            " 1-grams: ['$', 'I', '$', 'd', 'o', '$', 'n', 'o', 't', '$', 'l', 'i', 'k', 'e', '$', 't', 'h', 'e', 'm', ',', '$', 'S', 'a', 'm', '$', 'I', '$', 'a', 'm', '.', '$']\n",
            " 2-grams: ['$I', 'I$', '$d', 'do', 'o$', '$n', 'no', 'ot', 't$', '$l', 'li', 'ik', 'ke', 'e$', '$t', 'th', 'he', 'em', 'm,', ',$', '$S', 'Sa', 'am', 'm$', '$I', 'I$', '$a', 'am', 'm.', '.$']\n",
            " 3-grams: ['$I$', 'I$d', '$do', 'do$', 'o$n', '$no', 'not', 'ot$', 't$l', '$li', 'lik', 'ike', 'ke$', 'e$t', '$th', 'the', 'hem', 'em,', 'm,$', ',$S', '$Sa', 'Sam', 'am$', 'm$I', '$I$', 'I$a', '$am', 'am.', 'm.$']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 01 Part B(Jaccard Coefficient)\n",
        "doc1 = \"I am sam\"\n",
        "doc2 = \"Sam i am\"\n",
        "doc3 = \"I do not like green eggs and ham\"\n",
        "doc4 = \"I do not like them, Sam I am\"\n",
        "\n",
        "def jaccard(x,y):\n",
        "  x = x.lower()\n",
        "  y = y.lower()\n",
        "\n",
        "  #split the sentence in to words and create a list\n",
        "  x = set(x.split())\n",
        "  y = set(y.split())\n",
        "\n",
        "  #find the intersection\n",
        "  a=x.intersection(y)\n",
        "  #find the union\n",
        "  b=x.union(y)\n",
        "  return len(a)/len(b)\n",
        "\n",
        "j_value = jaccard(doc2, doc3)\n",
        "\n",
        "print(j_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTFpgJaIJPj7",
        "outputId": "a156ea73-9351-4ad2-b171-5e5a4c2d7895"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Exact Answer\n",
        "from nltk.util import ngrams\n",
        "\n",
        "# Function to generate k-grams\n",
        "def grams(doc, k):\n",
        "    doc = \"$\" + doc.replace(\" \", \"$\") + \"$\"\n",
        "    grammed_str = ngrams(doc.lower(), k)  # lowercased + character-level\n",
        "    grammed_list = {\"\".join(i) for i in grammed_str}  # set for uniqueness\n",
        "    return grammed_list\n",
        "\n",
        "# Jaccard coefficient for k-grams\n",
        "def jaccard(doc1, doc2, k):\n",
        "    g1 = grams(doc1, k)\n",
        "    g2 = grams(doc2, k)\n",
        "    intersection = g1.intersection(g2)\n",
        "    union = g1.union(g2)\n",
        "    return len(intersection) / len(union)\n",
        "\n",
        "# Example: Jaccard similarity between doc2 and doc3\n",
        "doc2 = \"Sam I am\"\n",
        "doc3 = \"I do not like green eggs and ham\"\n",
        "\n",
        "for k in [1, 2, 3]:\n",
        "    print(f\"Jaccard (k={k}) =\", jaccard(doc2, doc3, k))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwPw742nSH7n",
        "outputId": "326090bc-1924-4f97-c378-2c9a8c6dccfc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard (k=1) = 0.3333333333333333\n",
            "Jaccard (k=2) = 0.14285714285714285\n",
            "Jaccard (k=3) = 0.05405405405405406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 03(Levenshtein Algorithm)\n",
        "from nltk.metrics.distance import edit_distance\n",
        "\n",
        "print(edit_distance('python','pythonly'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ERptwJXSzKq",
        "outputId": "f917feb1-9d01-40be-c302-00dea00569bd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using python-Levenshtein library\n",
        "import pip\n",
        "pip.main([\"install\", \"Levenshtein\"])   # <-- tries to install the package\n",
        "from Levenshtein import distance\n",
        "print(distance('python','pythonly'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "-9YprFfyVGjr",
        "outputId": "42d483a9-5c8d-4d15-da5d-ebb5e0ff2781"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
            "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
            "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Requirement already satisfied: Levenshtein in /usr/local/lib/python3.12/dist-packages (0.27.1)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: Levenshtein in /usr/local/lib/python3.12/dist-packages (0.27.1)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from Levenshtein) (3.14.1)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: rapidfuzz&lt;4.0.0,&gt;=3.9.0 in /usr/local/lib/python3.12/dist-packages (from Levenshtein) (3.14.1)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 03(Soundex Algorithm)\n",
        "\n",
        "def soundex(word: str) -> str:  # -> str {It says: “This function will return a string.”}\n",
        " \"\"\"\n",
        " Soundex implementation (slide version):\n",
        " 1) Retain first letter (uppercase).\n",
        " 2) Change A,E,I,O,U,H,W,Y -> '0'\n",
        " 3) Map letters to digits:\n",
        " B,F,P,V -> 1\n",
        " C,G,J,K,Q,S,X,Z -> 2\n",
        " D,T -> 3\n",
        " L -> 4\n",
        " M,N -> 5\n",
        " R -> 6\n",
        " 4) Remove pairs of consecutive duplicate digits.\n",
        " 5) Remove all zeros.\n",
        " 6) Pad with trailing zeros and return first four characters: LDDD\n",
        " \"\"\"\n",
        " if not word:\n",
        "  return \"0000\"\n",
        " w = word.strip() #removes leading and trailing whitespace\n",
        "\n",
        " if not w:\n",
        "  return \"0000\"\n",
        "\n",
        " first = w[0].upper() #Saves the first letter (in uppercase)\n",
        "\n",
        " groups = { #Defines the mapping of consonants → digits.\n",
        " 'B': '1', 'F': '1', 'P': '1', 'V': '1',\n",
        " 'C': '2', 'G': '2', 'J': '2', 'K': '2',\n",
        " 'Q': '2', 'S': '2', 'X': '2', 'Z': '2',\n",
        " 'D': '3', 'T': '3',\n",
        " 'L': '4',\n",
        " 'M': '5', 'N': '5',\n",
        " 'R': '6'\n",
        " }\n",
        " zeros = set(\"AEIOUHWY\")\n",
        "\n",
        " encoded = []\n",
        " for ch in w[1:].upper():\n",
        "  if ch in zeros:\n",
        "    encoded.append('0')\n",
        "  else:\n",
        "    #get() --> retrieve a value related to a key\n",
        "    encoded.append(groups.get(ch, ''))\n",
        "\n",
        " dedup = []\n",
        " last = None\n",
        " for d in encoded:\n",
        "  if d == '' :\n",
        "    continue\n",
        "  if d != last:\n",
        "    dedup.append(d)\n",
        "    last = d\n",
        "#Removes consecutive duplicate digits.\n",
        "#Example: \"Pfaff\" → [\"1\",\"1\",\"0\",\"1\",\"1\"] → deduplicated → [\"1\",\"0\",\"1\"].\n",
        " dedup_no_zeros = [d for d in dedup if d != '0']\n",
        " code = first + \"\".join(dedup_no_zeros) #Builds the final code: first letter + digits.\n",
        " code = (code + \"0000\")[:4]\n",
        " return code\n"
      ],
      "metadata": {
        "id": "hw5BvYP3VgNw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(soundex(\"herman\"))\n",
        "print(soundex(\"harman\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBMuC3yuacSV",
        "outputId": "890eb9b8-f834-4e37-d7e4-3a05d592aa12"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H655\n",
            "H655\n"
          ]
        }
      ]
    }
  ]
}
